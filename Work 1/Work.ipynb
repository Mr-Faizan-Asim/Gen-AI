{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Star\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "nltk.download('brown')\n",
    "\n",
    "categories = brown.categories()\n",
    "\n",
    "print(categories)\n",
    "\n",
    "words = brown.words(categories='news')\n",
    "\n",
    "print(words[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcategories\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'categories' is not defined"
     ]
    }
   ],
   "source": [
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "text = \"Hello! How are you doing today? I hope you're well. This is an example sentence.\"\n",
    "\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "words = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "print(\"Sentences:\", sentences)\n",
    "print(\"Words:\", words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "preprocessed_sentences = []\n",
    "\n",
    "for sentence in tokenized_sentences:\n",
    "    stemmed_words = [stemmer.stem(word) for word in sentence]\n",
    "    \n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
    "    \n",
    "    filtered_words = [word for word in lemmatized_words if word.lower() not in stop_words]\n",
    "    \n",
    "    preprocessed_sentences.append(filtered_words)\n",
    "\n",
    "print(\"Original Sentences:\", sentences)\n",
    "print(\"Tokenized Words:\", tokenized_sentences)\n",
    "print(\"Stemmed Words:\", [stemmer.stem(word) for sentence in tokenized_sentences for word in sentence])\n",
    "print(\"Lemmatized Words:\", [lemmatizer.lemmatize(stemmer.stem(word)) for sentence in tokenized_sentences for word in sentence])\n",
    "print(\"Preprocessed Sentences:\", preprocessed_sentences)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
